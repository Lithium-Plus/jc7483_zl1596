{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time.\n",
    "start = time. time()\n",
    "\n",
    "\n",
    "meta = pd.read_csv(\"./AutoKaggle - Metadata.csv\")\n",
    "arrOfRows = [64,360]\n",
    "row = 360\n",
    "\n",
    "def preprocessing(row):\n",
    "    find_row = meta.loc[row]\n",
    "    train = ''\n",
    "    test = None\n",
    "    check_test = True\n",
    "    train_X = ''\n",
    "    train_Y = ''\n",
    "    test_X = None\n",
    "    if meta['name'].loc[row] == 'kobe-bryant-shot-selection':\n",
    "        train = pd.read_csv(\"./kobe-bryant-shot-selection/data/data.csv\")\n",
    "        check_test = False\n",
    "    elif meta['name'].loc[row] == 'mercedes-benz-greener-manufacturing':\n",
    "        train = pd.read_csv(\"./mercedes-benz-greener-manufacturing/data/train.csv\")\n",
    "        test = pd.read_csv(\"./mercedes-benz-greener-manufacturing/data/test.csv\")\n",
    "        \n",
    "    train = train.dropna()\n",
    "    if check_test:\n",
    "        test = test.dropna()\n",
    "    for c in train.columns:\n",
    "\n",
    "        if train[c].dtype == 'object':    # deal with text\n",
    "            lbl = LabelEncoder() \n",
    "            if check_test:\n",
    "                lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "                train[c] = lbl.transform(list(train[c].values))\n",
    "                test[c] = lbl.transform(list(test[c].values))\n",
    "            else:\n",
    "                lbl.fit(list(train[c].values))\n",
    "                train[c] = lbl.transform(list(train[c].values))\n",
    "\n",
    "    targetName = find_row['targetName']\n",
    "    train_Y = train[targetName]\n",
    "    train_X = train.drop(columns=targetName)\n",
    "    if check_test:\n",
    "        test_X = test\n",
    "        return train_X, train_Y, test_X\n",
    "    else:\n",
    "        return train_X, train_Y, None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(row,X_train, X_test):\n",
    "    if type(meta[\"function call feature extraction\"].loc[row]) is not str:\n",
    "        print('not func')\n",
    "        return X_train,X_test\n",
    "    extraction_function_calls = str(meta[\"function call feature extraction\"].loc[row])\n",
    "    extraction_function_calls = extraction_function_calls.split(\",\")\n",
    "    extraction_funtion_param = eval(meta[\"function parameters feature extraction\"].loc[row])\n",
    "    function_nums = len(extraction_function_calls)\n",
    "    for i in range(function_nums):\n",
    "        str1 = extraction_function_calls[i]\n",
    "        str2 = extraction_funtion_param[i]\n",
    "        l_str = str1.split(\"(\")\n",
    "        l_str.insert(1,\"(\"+str2)\n",
    "        str_call = ''\n",
    "        str_call = str_call.join(l_str)\n",
    "        str_call = 'extractor' + '=' + str_call\n",
    "        exec(str_call, globals(), globals())\n",
    "        extracted_train = extractor.fit_transform(X_train)\n",
    "        n_comp = extracted_train.shape[1]\n",
    "        for j in range(0, n_comp):\n",
    "            X_train['extractor'+ str(i)+\"_\"+str(j)] = extracted_train[:, j]\n",
    "        if X_test is not None:\n",
    "            extracted_test = extractor.fit_transform(X_test)\n",
    "            for j in range(0, n_comp):\n",
    "                X_test['extractor'+ str(i)+\"_\"+str(j)] = extracted_test[:, j]\n",
    "            return X_train,X_test\n",
    "        else:\n",
    "            return X_train,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(row,X_train,X_test,Y_train):\n",
    "    estimation_function_calls = meta[\"function calls estimation\"].loc[row]\n",
    "    estimation_function_calls = estimation_function_calls.split(\",\")\n",
    "    print(type(meta[\"function parameters estimation\"].loc[row]))\n",
    "    print(meta[\"function parameters estimation\"].loc[row])\n",
    "    estimation_function_param = eval(meta[\"function parameters estimation\"].loc[row])\n",
    "    \n",
    "    print(len(estimation_function_calls))\n",
    "    if len(estimation_function_calls) == 1:\n",
    "        l_str = estimation_function_calls[0].split(\"(\")\n",
    "        l_str.insert(1,'('+estimation_function_param[0])\n",
    "        str_call = ''\n",
    "        str_call = str_call.join(l_str)\n",
    "        str_call = 'estimator' + '=' + str_call\n",
    "        exec(str_call,globals(),globals())\n",
    "#         estimator.fit(X_train,Y_train)\n",
    "        print(cross_val_score(estimator, X_train, Y_train, cv=3, n_jobs=8))\n",
    "    else:\n",
    "        estimators = []\n",
    "        n_estimators = len(estimation_function_calls)\n",
    "        for i in range(n_estimators):\n",
    "            str1 = extraction_function_calls\n",
    "            str2 = extraction_funtion_param\n",
    "            l_str = str1.split(\"(\")\n",
    "            l_str.insert(1,\"(\"+str2)\n",
    "            str_call = ''\n",
    "            str_call = str_call.join(l_str)\n",
    "            str_call = 'estimator' + '=' + str_call\n",
    "            print(l_str)\n",
    "            print(str_call)\n",
    "            exec(str_call)\n",
    "            estimators.append(estimator)\n",
    "            postprocessing(estimators,stack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not func\n",
      "<class 'str'>\n",
      "['max_depth=7, learning_rate=0.012, n_estimators=1000, subsample=0.62, colsample_bytree=0.6, seed=1']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test = preprocessing(row)\n",
    "X_train_selected, X_test_selected = feature_extraction(row,X_train,X_test)\n",
    "Y_pred = estimation(row,X_train_selected,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(estimators,stack):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time. time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
